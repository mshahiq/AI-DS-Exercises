{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Classifier\n",
    "\n",
    "In this notebook you will create both, an mnist tabular dataset and a classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.- import the Operating System (os) module in python and any other library you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.- As you can see each class has its own folder (Do it only for train). \n",
    "\n",
    "    - Iterate folder by folder ( os.listdir() )\n",
    "    - Inside each folder: \n",
    "        1.- Read the image\n",
    "        2.- Reshape it into a flat array (784,)\n",
    "        3.- Save the data into a pandas dataframe apending the column name as the class\n",
    "    - Save the data into a CSV\n",
    "\n",
    "    Note: if it takes to long try doing only 100 images per folder for the CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "directory = 'D:/AI-Course/AI-Engineering/AI-Engineering/Chapter 2/12. Images/archive/trainingSet/trainingSet/'\n",
    "\n",
    "dir_list = os.listdir(directory)                  # determine the number of folder in the given directory\n",
    "\n",
    "df1 = pd.DataFrame()                              # initial DF\n",
    "\n",
    "for file in dir_list:\n",
    "    imgs = os.listdir(directory+file)             # reading from directory --> Files, the images.\n",
    "\n",
    "    arr = np.zeros((len(imgs),785))               # builds an array with 0 according to the dimensions of image and 785 (1+784)\n",
    "    for i,img in enumerate(imgs):\n",
    "        imag = Image.open(directory+file+'/'+img) # in iteration loop, open every image\n",
    "        arry = np.array(imag,dtype=float)         \n",
    "        # print(arry.shape)                       # to get the actual shape\n",
    "        arry = arry.flatten()                     # changes the shape to (784,)\n",
    "        arr[i,:784]=arry                          # reading from first column till 783 column\n",
    "        arr[i,784]=int(file)                      # reading the last column 784\n",
    "    df2 = pd.DataFrame(data=arr)                  # building a temporary DF\n",
    "    df = pd.concat([df1,df2])                     # merging the results in original DF\n",
    "    df1 = df\n",
    "    #print(df.shape)\n",
    "\n",
    "df1.to_csv('data.csv',index=False, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.- Load the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8     9    ...  775  776  777  778  \\\n",
       "0  3.0  0.0  0.0  3.0  7.0  3.0  0.0  3.0  0.0  11.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  8.0   0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  2.0   0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   9.0  ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   2.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   779  780  781  782  783  784  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = pd.read_csv ('data.csv',header = None)\n",
    "X = values.iloc[:,:-1]\n",
    "y = values.iloc[:,-1]\n",
    "values.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.- Create a dictionary of models (No preprocessing needed, it has already been done).\n",
    "    \n",
    "    Include both, tree models and mult models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble         import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree             import DecisionTreeClassifier\n",
    "from catboost                 import CatBoostClassifier\n",
    "from xgboost                  import XGBClassifier\n",
    "from lightgbm                 import LGBMClassifier\n",
    "from sklearn.svm              import SVC\n",
    "from sklearn.linear_model     import LogisticRegression\n",
    "from sklearn.neighbors        import KNeighborsClassifier\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn                  import metrics\n",
    "import time\n",
    "\n",
    "tree_classifiers = {\n",
    "  \"Random Forest\":        RandomForestClassifier(n_estimators=100),\n",
    "  \"AdaBoost\":             AdaBoostClassifier(n_estimators=100),\n",
    "  \"Skl GBM\":              GradientBoostingClassifier(n_estimators=100),\n",
    "  \"Decision Tree\":        DecisionTreeClassifier(),\n",
    "  \"CatBoost\":             CatBoostClassifier(n_estimators=100),\n",
    "  \"XGBoost\":              XGBClassifier(n_estimators=100),\n",
    "  \"LightGBM\":             LGBMClassifier(n_estimators=100),\n",
    "  \"SVM\":                  SVC(),\n",
    "  \"Logistic Regression\":  LogisticRegression(),\n",
    "  \"KNN\":                  KNeighborsClassifier(n_neighbors=3)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.- Using either cross validation or stratification find out which is the best model\n",
    "    - Base your code on the previous two days examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.5\n",
      "0:\tlearn: 1.4307139\ttotal: 6.14s\tremaining: 10m 8s\n",
      "1:\tlearn: 1.0650109\ttotal: 10.8s\tremaining: 8m 48s\n",
      "2:\tlearn: 0.8672597\ttotal: 14.7s\tremaining: 7m 55s\n",
      "3:\tlearn: 0.7117051\ttotal: 18.7s\tremaining: 7m 29s\n",
      "4:\tlearn: 0.6363522\ttotal: 22.8s\tremaining: 7m 12s\n",
      "5:\tlearn: 0.5581984\ttotal: 26.8s\tremaining: 6m 59s\n",
      "6:\tlearn: 0.5070194\ttotal: 30.8s\tremaining: 6m 48s\n",
      "7:\tlearn: 0.4589989\ttotal: 34.7s\tremaining: 6m 39s\n",
      "8:\tlearn: 0.4270370\ttotal: 38.8s\tremaining: 6m 31s\n",
      "9:\tlearn: 0.3959495\ttotal: 42.7s\tremaining: 6m 24s\n",
      "10:\tlearn: 0.3674313\ttotal: 46.7s\tremaining: 6m 17s\n",
      "11:\tlearn: 0.3421192\ttotal: 50.7s\tremaining: 6m 12s\n",
      "12:\tlearn: 0.3208680\ttotal: 54.8s\tremaining: 6m 6s\n",
      "13:\tlearn: 0.3016118\ttotal: 59.1s\tremaining: 6m 3s\n",
      "14:\tlearn: 0.2904509\ttotal: 1m 3s\tremaining: 5m 57s\n",
      "15:\tlearn: 0.2765036\ttotal: 1m 7s\tremaining: 5m 51s\n",
      "16:\tlearn: 0.2673874\ttotal: 1m 10s\tremaining: 5m 46s\n",
      "17:\tlearn: 0.2594287\ttotal: 1m 14s\tremaining: 5m 41s\n",
      "18:\tlearn: 0.2534564\ttotal: 1m 18s\tremaining: 5m 35s\n",
      "19:\tlearn: 0.2405850\ttotal: 1m 22s\tremaining: 5m 30s\n",
      "20:\tlearn: 0.2353766\ttotal: 1m 26s\tremaining: 5m 26s\n",
      "21:\tlearn: 0.2287059\ttotal: 1m 30s\tremaining: 5m 21s\n",
      "22:\tlearn: 0.2253805\ttotal: 1m 34s\tremaining: 5m 16s\n",
      "23:\tlearn: 0.2182317\ttotal: 1m 38s\tremaining: 5m 11s\n",
      "24:\tlearn: 0.2176544\ttotal: 1m 42s\tremaining: 5m 7s\n",
      "25:\tlearn: 0.2102422\ttotal: 1m 46s\tremaining: 5m 2s\n",
      "26:\tlearn: 0.2064090\ttotal: 1m 50s\tremaining: 4m 58s\n",
      "27:\tlearn: 0.2041493\ttotal: 1m 54s\tremaining: 4m 53s\n",
      "28:\tlearn: 0.2011980\ttotal: 1m 58s\tremaining: 4m 49s\n",
      "29:\tlearn: 0.1998677\ttotal: 2m 1s\tremaining: 4m 44s\n",
      "30:\tlearn: 0.1988866\ttotal: 2m 5s\tremaining: 4m 40s\n",
      "31:\tlearn: 0.1973972\ttotal: 2m 9s\tremaining: 4m 35s\n",
      "32:\tlearn: 0.1948580\ttotal: 2m 13s\tremaining: 4m 30s\n",
      "33:\tlearn: 0.1916763\ttotal: 2m 17s\tremaining: 4m 26s\n",
      "34:\tlearn: 0.1856837\ttotal: 2m 21s\tremaining: 4m 22s\n",
      "35:\tlearn: 0.1849664\ttotal: 2m 24s\tremaining: 4m 17s\n",
      "36:\tlearn: 0.1837172\ttotal: 2m 28s\tremaining: 4m 13s\n",
      "37:\tlearn: 0.1811980\ttotal: 2m 32s\tremaining: 4m 9s\n",
      "38:\tlearn: 0.1807934\ttotal: 2m 36s\tremaining: 4m 4s\n",
      "39:\tlearn: 0.1788200\ttotal: 2m 40s\tremaining: 4m\n",
      "40:\tlearn: 0.1779758\ttotal: 2m 44s\tremaining: 3m 56s\n",
      "41:\tlearn: 0.1773079\ttotal: 2m 47s\tremaining: 3m 51s\n",
      "42:\tlearn: 0.1769507\ttotal: 2m 51s\tremaining: 3m 47s\n",
      "43:\tlearn: 0.1758540\ttotal: 2m 55s\tremaining: 3m 43s\n",
      "44:\tlearn: 0.1741339\ttotal: 2m 59s\tremaining: 3m 39s\n",
      "45:\tlearn: 0.1732543\ttotal: 3m 3s\tremaining: 3m 35s\n",
      "46:\tlearn: 0.1728589\ttotal: 3m 7s\tremaining: 3m 30s\n",
      "47:\tlearn: 0.1708652\ttotal: 3m 10s\tremaining: 3m 26s\n",
      "48:\tlearn: 0.1698277\ttotal: 3m 14s\tremaining: 3m 22s\n",
      "49:\tlearn: 0.1686747\ttotal: 3m 18s\tremaining: 3m 18s\n",
      "50:\tlearn: 0.1680644\ttotal: 3m 22s\tremaining: 3m 14s\n",
      "51:\tlearn: 0.1673883\ttotal: 3m 26s\tremaining: 3m 10s\n",
      "52:\tlearn: 0.1651256\ttotal: 3m 29s\tremaining: 3m 5s\n",
      "53:\tlearn: 0.1645597\ttotal: 3m 33s\tremaining: 3m 1s\n",
      "54:\tlearn: 0.1640103\ttotal: 3m 36s\tremaining: 2m 57s\n",
      "55:\tlearn: 0.1630824\ttotal: 3m 40s\tremaining: 2m 53s\n",
      "56:\tlearn: 0.1623343\ttotal: 3m 44s\tremaining: 2m 49s\n",
      "57:\tlearn: 0.1610087\ttotal: 3m 48s\tremaining: 2m 45s\n",
      "58:\tlearn: 0.1602995\ttotal: 3m 52s\tremaining: 2m 41s\n",
      "59:\tlearn: 0.1596097\ttotal: 3m 56s\tremaining: 2m 37s\n",
      "60:\tlearn: 0.1591458\ttotal: 3m 59s\tremaining: 2m 33s\n",
      "61:\tlearn: 0.1578676\ttotal: 4m 3s\tremaining: 2m 29s\n",
      "62:\tlearn: 0.1575933\ttotal: 4m 7s\tremaining: 2m 25s\n",
      "63:\tlearn: 0.1571773\ttotal: 4m 11s\tremaining: 2m 21s\n",
      "64:\tlearn: 0.1562506\ttotal: 4m 15s\tremaining: 2m 17s\n",
      "65:\tlearn: 0.1550122\ttotal: 4m 18s\tremaining: 2m 13s\n",
      "66:\tlearn: 0.1543241\ttotal: 4m 22s\tremaining: 2m 9s\n",
      "67:\tlearn: 0.1536760\ttotal: 4m 26s\tremaining: 2m 5s\n",
      "68:\tlearn: 0.1520734\ttotal: 4m 30s\tremaining: 2m 1s\n",
      "69:\tlearn: 0.1512120\ttotal: 4m 34s\tremaining: 1m 57s\n",
      "70:\tlearn: 0.1505787\ttotal: 4m 38s\tremaining: 1m 53s\n",
      "71:\tlearn: 0.1499326\ttotal: 4m 42s\tremaining: 1m 49s\n",
      "72:\tlearn: 0.1488548\ttotal: 4m 45s\tremaining: 1m 45s\n",
      "73:\tlearn: 0.1486345\ttotal: 4m 49s\tremaining: 1m 41s\n",
      "74:\tlearn: 0.1482282\ttotal: 4m 53s\tremaining: 1m 37s\n",
      "75:\tlearn: 0.1478873\ttotal: 4m 57s\tremaining: 1m 33s\n",
      "76:\tlearn: 0.1473957\ttotal: 5m 1s\tremaining: 1m 29s\n",
      "77:\tlearn: 0.1468214\ttotal: 5m 4s\tremaining: 1m 26s\n",
      "78:\tlearn: 0.1459083\ttotal: 5m 8s\tremaining: 1m 22s\n",
      "79:\tlearn: 0.1456219\ttotal: 5m 12s\tremaining: 1m 18s\n",
      "80:\tlearn: 0.1454686\ttotal: 5m 16s\tremaining: 1m 14s\n",
      "81:\tlearn: 0.1451618\ttotal: 5m 20s\tremaining: 1m 10s\n",
      "82:\tlearn: 0.1446305\ttotal: 5m 24s\tremaining: 1m 6s\n",
      "83:\tlearn: 0.1439502\ttotal: 5m 28s\tremaining: 1m 2s\n",
      "84:\tlearn: 0.1437338\ttotal: 5m 31s\tremaining: 58.6s\n",
      "85:\tlearn: 0.1433558\ttotal: 5m 35s\tremaining: 54.6s\n",
      "86:\tlearn: 0.1420858\ttotal: 5m 39s\tremaining: 50.7s\n",
      "87:\tlearn: 0.1417116\ttotal: 5m 43s\tremaining: 46.8s\n",
      "88:\tlearn: 0.1411393\ttotal: 5m 47s\tremaining: 42.9s\n",
      "89:\tlearn: 0.1409775\ttotal: 5m 51s\tremaining: 39s\n",
      "90:\tlearn: 0.1402475\ttotal: 5m 54s\tremaining: 35.1s\n",
      "91:\tlearn: 0.1398426\ttotal: 5m 58s\tremaining: 31.2s\n",
      "92:\tlearn: 0.1394072\ttotal: 6m 2s\tremaining: 27.3s\n",
      "93:\tlearn: 0.1392391\ttotal: 6m 6s\tremaining: 23.4s\n",
      "94:\tlearn: 0.1380600\ttotal: 6m 10s\tremaining: 19.5s\n",
      "95:\tlearn: 0.1377698\ttotal: 6m 14s\tremaining: 15.6s\n",
      "96:\tlearn: 0.1373205\ttotal: 6m 18s\tremaining: 11.7s\n",
      "97:\tlearn: 0.1369767\ttotal: 6m 21s\tremaining: 7.79s\n",
      "98:\tlearn: 0.1368061\ttotal: 6m 25s\tremaining: 3.9s\n",
      "99:\tlearn: 0.1364849\ttotal: 6m 29s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\anaconda3\\envs\\strive\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:46:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\anaconda3\\envs\\strive\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy[%]</th>\n",
       "      <th>Bal Accuracy [%]</th>\n",
       "      <th>Time [s]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>95.833333</td>\n",
       "      <td>95.805150</td>\n",
       "      <td>43.020005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>73.130952</td>\n",
       "      <td>72.836665</td>\n",
       "      <td>175.419226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Skl GBM</td>\n",
       "      <td>93.785714</td>\n",
       "      <td>93.725907</td>\n",
       "      <td>3130.605723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>83.940476</td>\n",
       "      <td>83.739950</td>\n",
       "      <td>19.304379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>93.833333</td>\n",
       "      <td>93.790959</td>\n",
       "      <td>390.651377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>96.821429</td>\n",
       "      <td>96.810514</td>\n",
       "      <td>561.856497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>97.202381</td>\n",
       "      <td>97.186757</td>\n",
       "      <td>103.048588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM</td>\n",
       "      <td>97.547619</td>\n",
       "      <td>97.524004</td>\n",
       "      <td>138.337261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>91.726190</td>\n",
       "      <td>91.634824</td>\n",
       "      <td>9.015657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNN</td>\n",
       "      <td>96.250000</td>\n",
       "      <td>96.194329</td>\n",
       "      <td>13.198211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy[%]  Bal Accuracy [%]     Time [s]\n",
       "0        Random Forest    95.833333         95.805150    43.020005\n",
       "1             AdaBoost    73.130952         72.836665   175.419226\n",
       "2              Skl GBM    93.785714         93.725907  3130.605723\n",
       "3        Decision Tree    83.940476         83.739950    19.304379\n",
       "4             CatBoost    93.833333         93.790959   390.651377\n",
       "5              XGBoost    96.821429         96.810514   561.856497\n",
       "6             LightGBM    97.202381         97.186757   103.048588\n",
       "7                  SVM    97.547619         97.524004   138.337261\n",
       "8  Logistic Regression    91.726190         91.634824     9.015657\n",
       "9                  KNN    96.250000         96.194329    13.198211"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0, stratify=y)\n",
    "\n",
    "\n",
    "def predictions(data):\n",
    "    results = pd.DataFrame(columns=['Model','Accuracy[%]','Bal Accuracy [%]','Time [s]'])\n",
    "\n",
    "    for model_name, model in tree_classifiers.items():\n",
    "        start_time = time.time()\n",
    "\n",
    "        model.fit(X_train,y_train) \n",
    "\n",
    "        pred = model.predict(data) # get the predicitons using x values\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "\n",
    "        results = results.append({\"Model\":model_name, \"Accuracy[%]\": metrics.accuracy_score(y_test, pred)*100, \"Bal Accuracy [%]\": metrics.balanced_accuracy_score(y_test, pred)*100,\"Time [s]\":total_time},ignore_index=True)\n",
    "    return results\n",
    "final_results = predictions(X_test)\n",
    "final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Can you rotate an image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7016010205a98451d52b0c4cab227365108095c7ad70437c80600f3976844f69"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('strive': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
